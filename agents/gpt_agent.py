"""GPT ê¸°ë°˜ ì¢…í•© ë¶„ì„ ì „ë¬¸ê°€ Agent"""

import openai
from typing import Dict, List, Optional, Any
from agents.base_agent import BaseAgent, AgentConfig, AgentResponse, AgentError
from config.settings import LLM_CONFIGS
from utils.knowledge_connector import get_knowledge_connector
import logging

logger = logging.getLogger(__name__)

class GPTAgent(BaseAgent):
    """GPT ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë° ë…¼ë¦¬ì  í•´ê²°ì±… ì „ë¬¸ê°€"""

    def __init__(self):
        config = AgentConfig(
            name="GPT",
            specialty="ì¢…í•© ë¶„ì„ ë° ë…¼ë¦¬ì  í•´ê²°ì±…",
            model=LLM_CONFIGS["openai"]["model"],
            max_tokens=LLM_CONFIGS["openai"]["max_tokens"],
            temperature=LLM_CONFIGS["openai"]["temperature"]
        )
        super().__init__(config)

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = openai.AsyncOpenAI(
            api_key=LLM_CONFIGS["openai"]["api_key"]
        )
        
        # Knowledge Connector ì´ˆê¸°í™”
        self.knowledge_connector = get_knowledge_connector()

    async def analyze_and_respond(self, state: Dict[str, Any]) -> AgentResponse:
        """GPT ê¸°ë°˜ ì¢…í•© ë¶„ì„"""

        self.validate_input(state)

        user_question = state.get('user_message', '')
        rag_context = state.get('rag_context', {})
        issue_classification = state.get('issue_classification', {})
        conversation_history = state.get('conversation_history', [])
        
        print(f"ğŸ” GPT Agent - conversation_history ìˆ˜: {len(conversation_history)}")
        if conversation_history:
            print(f"ğŸ” GPT Agent - ì²« ë²ˆì§¸ ëŒ€í™”: {conversation_history[0]}")
        else:
            print(f"ğŸ” GPT Agent - conversation_historyê°€ ë¹„ì–´ìˆìŒ")
        
        # ë™ì  í† í° í•œê³„ ê³„ì‚°
        from utils.token_manager import get_token_manager
        token_manager = get_token_manager()
        dynamic_max_tokens = token_manager.get_agent_specific_limit('gpt', state)

        # Knowledge Base ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        knowledge_context = self._get_knowledge_context(user_question, issue_classification or {})
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self.build_analysis_prompt(user_question, rag_context or {}, issue_classification or {}, conversation_history, knowledge_context)

        try:
            logger.info(f"GPT Agent ë¶„ì„ ì‹œì‘ - ëª¨ë¸: {self.model}")

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ êµ¬ì„±
            messages = [{"role": "system", "content": self.get_system_prompt()}]
            
            # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
            if conversation_history:
                for conv in conversation_history:
                    if isinstance(conv, dict):
                        if conv.get("role") and conv.get("content"):
                            messages.append(conv)
            
            # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
            messages.append({"role": "user", "content": prompt})

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.config.temperature,
                max_tokens=dynamic_max_tokens
            )

            response_text = response.choices[0].message.content
            token_usage = {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            }

            confidence = self.calculate_confidence(len(response_text), token_usage)

            logger.info(f"GPT Agent ë¶„ì„ ì™„ë£Œ - í† í° ì‚¬ìš©: {token_usage['total_tokens']}")

            return self.create_response(
                response_text=response_text,
                confidence=confidence,
                processing_time=0.0,  # ì‹¤ì œ ì‹œê°„ì€ base_agentì—ì„œ ê³„ì‚°
                token_usage=token_usage
            )

        except openai.RateLimitError as e:
            logger.error(f"GPT API ìš”ì²­ í•œë„ ì´ˆê³¼: {str(e)}")
            raise AgentError("API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", self.name, "RATE_LIMIT")

        except openai.AuthenticationError as e:
            logger.error(f"GPT API ì¸ì¦ ì˜¤ë¥˜: {str(e)}")
            raise AgentError("API ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", self.name, "AUTH_ERROR")

        except Exception as e:
            logger.error(f"GPT Agent ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            raise AgentError(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", self.name, "ANALYSIS_ERROR")

    def get_system_prompt(self) -> str:
        """GPT Agent ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì œì¡°ì—… ì¥ë¹„ ë¬¸ì œ í•´ê²° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        
ì „ë¬¸ì„±:
- ì¢…í•©ì ì´ê³  ë…¼ë¦¬ì ì¸ ë¬¸ì œ ë¶„ì„
- ë‹¨ê³„ë³„ í•´ê²° ë°©ë²• ì œì‹œ
- ì•ˆì „ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤
- ì²´ê³„ì ì´ê³  êµ¬ì¡°í™”ëœ ì ‘ê·¼
- ë‹¤ì–‘í•œ ê´€ì ì—ì„œì˜ ì¢…í•©ì  íŒë‹¨

ì‘ë‹µ ì‹œ ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
1. ë¬¸ì œ ìƒí™© ì •í™•í•œ ì§„ë‹¨
2. ë‹¨ê³„ë³„ í•´ê²° ë°©ë²• (ìš°ì„ ìˆœìœ„ í¬í•¨)
3. ì˜ˆìƒ ì†Œìš” ì‹œê°„ ë° í•„ìš” ìì›
4. ì•ˆì „ ì£¼ì˜ì‚¬í•­ (í•„ìˆ˜)
5. ì¥ê¸°ì  ì˜ˆë°© ë°©ì•ˆ
6. ìœ„í—˜ë„ í‰ê°€ ë° ëŒ€ì•ˆ ì œì‹œ

ì‘ë‹µì€ ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì‘ì„±í•˜ì„¸ìš”."""

    def build_analysis_prompt(self, question: str, rag_context: Dict, issue_info: Dict, conversation_history: Optional[List] = None, knowledge_context: str = "") -> str:
        """ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        # RAG ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
        context_text = ""
        if rag_context.get('chroma_results'):
            context_text += "ê´€ë ¨ ê¸°ìˆ  ë¬¸ì„œ:\n"
            for i, result in enumerate(rag_context['chroma_results'][:3], 1):
                # RAGResult ê°ì²´ì™€ dictionary ë‘˜ ë‹¤ ì²˜ë¦¬
                if hasattr(result, 'content'):
                    content = result.content[:300]
                else:
                    content = result.get('content', '')[:300]
                context_text += f"{i}. {content}...\n"

        if rag_context.get('elasticsearch_results'):
            context_text += "\nê´€ë ¨ í•´ê²° ì‚¬ë¡€:\n"
            for i, result in enumerate(rag_context['elasticsearch_results'][:3], 1):
                # RAGResult ê°ì²´ì™€ dictionary ë‘˜ ë‹¤ ì²˜ë¦¬
                if hasattr(result, 'content'):
                    content = result.content[:300]
                else:
                    content = result.get('content', '')[:300]
                context_text += f"{i}. {content}...\n"

        # ëŒ€í™” ê¸°ë¡ ì •ë¦¬
        conversation_context = ""
        if conversation_history:
            conversation_context = "\nì´ì „ ëŒ€í™” ê¸°ë¡:\n"
            for i, conv in enumerate(conversation_history[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ
                if isinstance(conv, dict):
                    user_msg = conv.get('user_message', '')
                    bot_response = conv.get('bot_response', '')
                    timestamp = conv.get('timestamp', '')
                    agents_used = conv.get('agents_used', [])
                    if user_msg:
                        conversation_context += f"{i}. [{timestamp[:16]}] ì‚¬ìš©ì: {user_msg}\n"
                        if bot_response:
                            conversation_context += f"   ì–´ì‹œìŠ¤í„´íŠ¸: {bot_response[:200]}...\n"
                        if agents_used:
                            conversation_context += f"   â†’ ì°¸ì—¬ ì „ë¬¸ê°€: {', '.join(agents_used)}\n"

        # ì´ìŠˆ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
        issue_context = ""
        if issue_info.get('issue_info') and not issue_info['issue_info'].get('error'):
            issue_data = issue_info['issue_info']
            issue_context = f"""
ì´ìŠˆ ì •ë³´:
- ë¬¸ì œ ìœ í˜•: {issue_data.get('description', '')}
- ì¹´í…Œê³ ë¦¬: {issue_data.get('category', '')}
- ì‹¬ê°ë„: {issue_data.get('severity', '')}
- ì¼ë°˜ì  ì›ì¸: {', '.join(issue_data.get('common_causes', []))}
- í‘œì¤€ í•´ê²°ì±…: {', '.join(issue_data.get('standard_solutions', []))}
- ì˜í–¥ ë¶€í’ˆ: {', '.join(issue_data.get('affected_components', []))}
"""

        return f"""
ì‚¬ìš©ì ì§ˆë¬¸: {question}

{conversation_context}

{issue_context}

ë°°ê²½ ì •ë³´:
{context_text}

{knowledge_context}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì œì¡°ì—… ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë¶„ì„í•˜ê³  í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
ì´ì „ ëŒ€í™”ê°€ ìˆë‹¤ë©´ ê·¸ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì—°ì†ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
íŠ¹íˆ ë‹¤ìŒ ì‚¬í•­ì„ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë¤„ì£¼ì„¸ìš”:

1. ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„
2. ì²´ê³„ì ì´ê³  ë‹¨ê³„ë³„ í•´ê²° ë°©ë²•
3. ì•ˆì „ì„±ê³¼ ì‹¤ìš©ì„±ì„ ëª¨ë‘ ê³ ë ¤í•œ ì ‘ê·¼
4. ì˜ˆë°©ì„ ìœ„í•œ ì¥ê¸°ì  ê´€ì 
5. ë¹„ìš©ê³¼ íš¨ê³¼ë¥¼ ê³ ë ¤í•œ ìš°ì„ ìˆœìœ„

ì „ë¬¸ì ì´ë©´ì„œë„ í˜„ì¥ì—ì„œ ì‹¤ì œë¡œ ì ìš© ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""

    def get_strengths(self) -> List[str]:
        """GPT Agentì˜ ê°•ì """
        return ["ì¢…í•©ì ë¶„ì„", "ë‹¨ê³„ì í•´ê²°", "ì•ˆì „ê³ ë ¤", "ë…¼ë¦¬ì ì‚¬ê³ ", "ì²´ê³„ì ì ‘ê·¼"]

    def get_focus_areas(self) -> List[str]:
        """GPT Agentì˜ ì¤‘ì  ì˜ì—­"""
        return ["ë¬¸ì œì§„ë‹¨", "í•´ê²°ì ˆì°¨", "ìœ„í—˜í‰ê°€", "ì˜ˆë°©ë°©ì•ˆ", "ì¢…í•©íŒë‹¨"]

    def calculate_confidence(self, response_length: int, token_usage: Optional[Dict[str, int]] = None) -> float:
        """GPT ì‘ë‹µ ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = 0.8  # GPTëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë†’ì€ ì‹ ë¢°ë„

        # ì‘ë‹µ ê¸¸ì´ ê¸°ë°˜ ì¡°ì •
        if response_length > 800:  # ì¶©ë¶„íˆ ìƒì„¸í•œ ì‘ë‹µ
            base_confidence += 0.1
        elif response_length < 200:  # ë„ˆë¬´ ê°„ë‹¨í•œ ì‘ë‹µ
            base_confidence -= 0.2

        # í† í° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ì¡°ì •
        if token_usage:
            completion_tokens = token_usage.get('completion_tokens', 0)
            if completion_tokens > 1000:  # ë§¤ìš° ìƒì„¸í•œ ë¶„ì„
                base_confidence += 0.05
            elif completion_tokens < 300:  # ê°„ë‹¨í•œ ì‘ë‹µ
                base_confidence -= 0.1

        return min(0.95, max(0.3, base_confidence))

    def _get_knowledge_context(self, question: str, issue_info: Dict) -> str:
        """Knowledge Baseì—ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            context_parts = []
            
            # ì¥ë¹„ íƒ€ì… ì¶”ì¶œ ì‹œë„
            equipment_type = None
            equipment_keywords = {
                'PRESS_HYDRAULIC': ['ìœ ì••', 'í”„ë ˆìŠ¤', 'press', 'hydraulic'],
                'PRESS_PRODUCTIVITY': ['ìƒì‚°ì„±', 'productivity', 'í”„ë ˆìŠ¤'],
                'WELDING_ROBOT_KAMP': ['ìš©ì ‘', 'ë¡œë´‡', 'welding', 'robot', 'kamp'],
                'PAINTING_COATING': ['ë„ì¥', 'ì½”íŒ…', 'painting', 'coating'],
                'PAINTING_EQUIPMENT': ['ë„ì¥ì¥ë¹„', 'painting equipment'],
                'ASSEMBLY_PARTS': ['ì¡°ë¦½', 'ë¶€í’ˆ', 'assembly', 'parts']
            }
            
            for eq_type, keywords in equipment_keywords.items():
                if any(keyword in question.lower() for keyword in keywords):
                    equipment_type = eq_type
                    break
            
            # ì´ìŠˆ ì½”ë“œì—ì„œ ì¥ë¹„ íƒ€ì… ì¶”ì¶œ
            issue_code = issue_info.get('issue_code') if issue_info else None
            if not equipment_type and issue_code:
                for eq_type in equipment_keywords.keys():
                    if eq_type.lower() in issue_code.lower():
                        equipment_type = eq_type
                        break
            
            # Knowledge Base ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            if equipment_type:
                kb_context = self.knowledge_connector.get_context_for_agent(
                    equipment_type=equipment_type,
                    issue_code=issue_code
                )
                if kb_context:
                    context_parts.append(f"[ì§€ì‹ë² ì´ìŠ¤ ì •ë³´]\n{kb_context}")
            
            # ì´ìŠˆë³„ í•´ê²°ì±… ê²€ìƒ‰
            if issue_code:
                solution_info = self.knowledge_connector.search_solutions(issue_code)
                if solution_info.get('found'):
                    issue_data = solution_info['issue']
                    context_parts.append(f"[í•´ê²°ì±… ë°ì´í„°ë² ì´ìŠ¤]\në¬¸ì œ: {issue_data.get('description', '')}")
                    if issue_data.get('standard_solutions'):
                        context_parts.append(f"í‘œì¤€ í•´ê²°ì±…: {', '.join(issue_data['standard_solutions'][:3])}")
            
            return "\n\n".join(context_parts) if context_parts else ""
            
        except Exception as e:
            logger.warning(f"Knowledge context ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return ""